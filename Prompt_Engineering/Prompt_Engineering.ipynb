{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "This notebook covers the essentials of prompt engineering, including some best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XRvKdaPDTznN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>‚ö†Ô∏è The kernel is going to restart. Please wait until it is finished before continuing to the next step. ‚ö†Ô∏è</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "Authenticate your environment on Google Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-00-94c787497e0b\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-east4\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QqRWdPGmW3NJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerationConfig, GenerativeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnFPpCRtXRl4"
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IQYu_9SvXQah",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-1.0-pro-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The sky is,\"\"\"\n",
    "\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place: Lisbon \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"\"\"\n",
    "Extract the all the name of places in the following text. \n",
    "\n",
    "Desired format:\n",
    "Place: <comma_separated_list_of_places>\n",
    "\n",
    "Input: \"Although these developments are encouraging to researchers, much is still a mystery. ‚ÄúWe often have a black box between the brain \n",
    "and the effect we see in the periphery,‚Äù says Henrique Veiga-Fernandes, a neuroimmunologist at the Champalimaud Centre for the Unknown in Lisbon. \n",
    "‚ÄúIf we want to use it in the therapeutic context, we actually need to understand the mechanism.‚Äú\"\n",
    "\"\"\"\n",
    "\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuuDhA37cvmP"
   },
   "source": [
    "# Reduce variability | Generative to Clacification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAmm9wPYc_1o"
   },
   "source": [
    "#### Classification tasks reduces output variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "kYDKh0r2dAqo",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Choosing the right programming language for you\n",
      "\n",
      "As a high school student, choosing the right programming language to learn can be exciting and overwhelming at the same time. All three options you mentioned, Python, JavaScript, and Fortran, have their strengths and weaknesses, and the best choice for you depends on your interests and goals.\n",
      "\n",
      "**Here's a breakdown of each language and what it's best suited for:**\n",
      "\n",
      "* **Python:**\n",
      "    * **Strengths:** \n",
      "        * **Easy to learn:** Python has a simple and readable syntax, making it a great choice for beginners.\n",
      "        * **Versatile:** Python can be used for a wide range of tasks, including web development, data analysis, machine learning, and scripting.\n",
      "        * **Large community:** Python has a huge and active community, which means there are plenty of resources available to help you learn and solve problems.\n",
      "    * **Weaknesses:**\n",
      "        * **Slower than compiled languages:** Python is an interpreted language, which means it can be slower than compiled languages like C++ or Java.\n",
      "        * **Not ideal for low-level programming:** Python is not well-suited for tasks that require direct hardware access, such as embedded systems programming.\n",
      "* **JavaScript:**\n",
      "    * **Strengths:**\n",
      "        * **Essential for web development:** JavaScript is the primary language used for adding interactivity to websites.\n",
      "        * **Widely used:** JavaScript is the most popular programming language in the world, so learning it opens up a wide range of career opportunities.\n",
      "        * **Relatively easy to learn:** While JavaScript has a steeper learning curve than Python, it's still considered a beginner-friendly language.\n",
      "    * **Weaknesses:**\n",
      "        * **Can be complex for beginners:** JavaScript has some quirks and complexities that can be challenging for new programmers.\n",
      "        * **Not as versatile as Python:** JavaScript is primarily used for web development, and while it can be used for other tasks, it's not as versatile as Python.\n",
      "* **Fortran:**\n",
      "    * **Strengths:**\n",
      "        * **High performance:** Fortran is a compiled language, which means it can be very fast.\n",
      "        * **Well-suited for scientific computing:** Fortran is widely used in scientific and engineering fields due to its speed and numerical accuracy.\n",
      "    * **Weaknesses:**\n",
      "        * **Difficult to learn:** Fortran has a complex syntax and requires a strong understanding of computer science concepts.\n",
      "        * **Limited career opportunities:** While Fortran is still used in some industries, it's not as widely used as Python or JavaScript, which can limit career opportunities.\n",
      "\n",
      "## Making your decision\n",
      "\n",
      "Based on your information, here are some factors to consider when making your decision:\n",
      "\n",
      "* **Your interests:**\n",
      "    * **Are you interested in web development?** If so, JavaScript is the best choice.\n",
      "    * **Do you want to learn a general-purpose language that can be used for a variety of tasks?** If so, Python is a good option.\n",
      "    * **Are you interested in scientific computing?** If so, Fortran is the best choice.\n",
      "* **Your learning style:**\n",
      "    * **Do you prefer a language with a simple and easy-to-read syntax?** If so, Python is a good choice.\n",
      "    * **Are you comfortable with a more challenging language?** If so, JavaScript or Fortran might be a better fit.\n",
      "* **Your career goals:**\n",
      "    * **What kind of job are you interested in?** Research the programming languages that are in demand for your desired career path.\n",
      "\n",
      "## My recommendation\n",
      "\n",
      "Based on your current information, I recommend starting with either Python or JavaScript.\n",
      "\n",
      "* **Python:** If you're new to programming and want to learn a versatile language with a large community, Python is a great choice. You can use it for web development, data analysis, machine learning, and much more.\n",
      "* **JavaScript:** If you're interested in web development and want to learn a widely used language with plenty of career opportunities, JavaScript is a good option. \n",
      "\n",
      "Remember, there's no single \"best\" language, and the best choice for you depends on your individual interests and goals. Take some time to research each language and try out some tutorials to see which one feels right for you.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"I'm a high school student. Which one of these activities do you suggest:\n",
    "a) learn Python\n",
    "b) learn JavaScript\n",
    "c) learn Fortran\n",
    "\"\"\"\n",
    "\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMbLginWdOKs"
   },
   "source": [
    "# Zero-shot prompt | No Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Crh2Loi2dQ0v"
   },
   "source": [
    "Below is an example of zero-shot prompting, where you don't provide any examples to the LLM within the prompt itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-7myRc-SdTQ4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive \n",
      "Explanation: The tweet expresses a positive opinion about the new YouTube video (\"loved\"). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I loved the new YouTube video you made!\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucRtPn9SdL64"
   },
   "source": [
    "# One-shot prompt | One Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rs0gQH2vdYBi"
   },
   "source": [
    "Below is an example of one-shot prompting, where you provide one example to the LLM within the prompt to give some guidance on what type of response you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "iEq-KxGYdaT5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: This is negative.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I loved the new YouTube video you made!\n",
    "Sentiment: This is a positive line.\n",
    "\n",
    "Tweet: That was awful. Super boring üò†\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnKLjJzmdfL_"
   },
   "source": [
    "# Few-shot prompt | More than one..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zv-9F5OdgI_"
   },
   "source": [
    "Below is an example of few-shot prompting, where you provide a few examples to the LLM within the prompt to give some guidance on what type of response you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "u37P9tG4dk9S",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I loved the new YouTube video you made!\n",
    "Sentiment: positive\n",
    "\n",
    "Tweet: That was awful. Super boring üò†\n",
    "Sentiment: negative\n",
    "\n",
    "Tweet: Something surprised me about this video - it was actually original. It was not the same old recycled stuff that I always see. Watch it - you will not regret it.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDMD3xb2dvX6"
   },
   "source": [
    "#### Choosing between zero-shot, one-shot, few-shot prompting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s92W0YpNdxJp"
   },
   "source": [
    "Which prompt technique to use will solely depends on your goal. The zero-shot prompts are more open-ended and can give you creative answers, while one-shot and few-shot prompts teach the model how to behave so you can get more predictable answers that are consistent with the examples provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting | Let's think step by step.\n",
    "intermediate reasoning steps than final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You went to the market and bought 10 apples. \n",
      "\n",
      "You then gave 2 apples to the neighbor, leaving you with 10 - 2 = 8 apples.\n",
      "\n",
      "You gave 2 more apples to the repairman, leaving you with 8 - 2 = 6 apples.\n",
      "\n",
      "You went and bought 5 more apples, increasing your total to 6 + 5 = 11 apples.\n",
      "\n",
      "Finally, you ate 1 apple, leaving you with a final total of 11 - 1 = 10 apples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\"\n",
    "I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
    "\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directional Prompting\n",
    "Hint: LLM, CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs can perform complex reasoning when prompted with a chain-of-thought (CoT) that guides them through step-by-step thinking. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\"\n",
    "Article:Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning\n",
    "steps. Providing these steps for prompting demonstrations is called chain-of-thought (CoT) prompting.\n",
    "CoT prompting has two major paradigms. One leverages a simple prompt like ‚ÄúLet‚Äôs think step by\n",
    "step‚Äù to facilitate step-by-step thinking before answering a question. The other uses a few manual\n",
    "demonstrations one by one, each composed of a question and a reasoning chain that leads to an\n",
    "answer. The superior performance of the second paradigm hinges on the hand-crafting of task-specific\n",
    "demonstrations one by one.\n",
    "\n",
    "Q: Summarize above article in one line based on hint.\n",
    "\n",
    "Hint: LLM, CoT\n",
    "\"\"\"\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cue\n",
    "Key takeaways are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Large language models (LLMs) can perform complex reasoning, with two main CoT prompting paradigms: step-by-step and demonstration-based.\n",
      "\n",
      "## Key takeaways:\n",
      "\n",
      "* LLMs can reason by generating intermediate steps.\n",
      "* Two CoT prompting paradigms exist: step-by-step and demonstration-based.\n",
      "* Demonstration-based prompting shows superior performance due to its task-specific nature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\"\n",
    "Article:Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning\n",
    "steps. Providing these steps for prompting demonstrations is called chain-of-thought (CoT) prompting.\n",
    "CoT prompting has two major paradigms. One leverages a simple prompt like ‚ÄúLet‚Äôs think step by\n",
    "step‚Äù to facilitate step-by-step thinking before answering a question. The other uses a few manual\n",
    "demonstrations one by one, each composed of a question and a reasoning chain that leads to an\n",
    "answer. The superior performance of the second paradigm hinges on the hand-crafting of task-specific\n",
    "demonstrations one by one.\n",
    "\n",
    "Summarize above article in one line.\n",
    "\n",
    "Key takeaways are:\n",
    "\"\"\"\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Double Down\n",
    "Summarize article in one humorous line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs are like toddlers, they need \"Let's think step by step\" prompts to help them reason. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\"\n",
    "Summarize article in one humorous line.\n",
    "\n",
    "Article:Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning\n",
    "steps. Providing these steps for prompting demonstrations is called chain-of-thought (CoT) prompting.\n",
    "CoT prompting has two major paradigms. One leverages a simple prompt like ‚ÄúLet‚Äôs think step by\n",
    "step‚Äù to facilitate step-by-step thinking before answering a question. The other uses a few manual\n",
    "demonstrations one by one, each composed of a question and a reasoning chain that leads to an\n",
    "answer. The superior performance of the second paradigm hinges on the hand-crafting of task-specific\n",
    "demonstrations one by one.\n",
    "\n",
    "Summarize article in one humorous line.\n",
    "\"\"\"\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Order Matters\n",
    "sad vs happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models can now perform complex reasoning by generating intermediate reasoning steps.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\"\n",
    "Summarize article in one sad line.\n",
    "\n",
    "Article:Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning\n",
    "steps. Providing these steps for prompting demonstrations is called chain-of-thought (CoT) prompting.\n",
    "CoT prompting has two major paradigms. One leverages a simple prompt like ‚ÄúLet‚Äôs think step by\n",
    "step‚Äù to facilitate step-by-step thinking before answering a question. The other uses a few manual\n",
    "demonstrations one by one, each composed of a question and a reasoning chain that leads to an\n",
    "answer. The superior performance of the second paradigm hinges on the hand-crafting of task-specific\n",
    "demonstrations one by one.\n",
    "\n",
    "Summarize article in one happy line.\n",
    "\"\"\"\n",
    "print(model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Give an ‚Äúout\n",
    "respond with \"not found\" if the answer is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article does not contain information about the cost of building LLMs.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\"\n",
    "\n",
    "Article:Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning\n",
    "steps. Providing these steps for prompting demonstrations is called chain-of-thought (CoT) prompting.\n",
    "CoT prompting has two major paradigms. One leverages a simple prompt like ‚ÄúLet‚Äôs think step by\n",
    "step‚Äù to facilitate step-by-step thinking before answering a question. The other uses a few manual\n",
    "demonstrations one by one, each composed of a question and a reasoning chain that leads to an\n",
    "answer. The superior performance of the second paradigm hinges on the hand-crafting of task-specific\n",
    "demonstrations one by one.\n",
    "\n",
    "QWhat is cost of builing LLM?.\n",
    "Respond with \"not found\" if the answer is not present\n",
    "\"\"\"\n",
    "print(model.generate_content(prompt).text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-16.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-16:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
